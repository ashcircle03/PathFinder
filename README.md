# PathFinder

**LangChain ê¸°ë°˜ ê³ ë“±í•™ìƒ ëŒ€í•™ í•™ê³¼ ì¶”ì²œ ì„œë¹„ìŠ¤**

## í”„ë¡œì íŠ¸ ê°œìš”

PathFinderëŠ” ê³ ë“±í•™ìƒë“¤ì˜ ê´€ì‹¬ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ ì í•©í•œ ëŒ€í•™ í•™ê³¼ë¥¼ ì¶”ì²œí•˜ëŠ” AI ê¸°ë°˜ ì§„ë¡œ ìƒë‹´ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

### ê¸°ìˆ  ìŠ¤íƒ

- **Frontend**: React + Vite (Nginx)
- **API**: FastAPI
- **LangChain**: RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„±
- **LLM**: Ollama + EXAONE-3.5-7.8B (LG AI í•œêµ­ì–´ ë„¤ì´í‹°ë¸Œ)
- **Vector DB**: Qdrant
- **Embeddings**: HuggingFace Sentence-Transformers (í•œêµ­ì–´ íŠ¹í™”)
- **ì»¨í…Œì´ë„ˆ**: Docker Compose (4ê°œ ì„œë¹„ìŠ¤)

---

## ì£¼ìš” ê¸°ëŠ¥

### ğŸ¯ LangChain RAG ì‹œìŠ¤í…œ

- **Retrieval (ê²€ìƒ‰)**: ì‚¬ìš©ì ê´€ì‹¬ì‚¬ì™€ ìœ ì‚¬í•œ í•™ê³¼ë¥¼ ë²¡í„° ê²€ìƒ‰
- **Augmentation (ì¦ê°•)**: ê²€ìƒ‰ëœ í•™ê³¼ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
- **Generation (ìƒì„±)**: LLMì´ ë§ì¶¤í˜• ì¶”ì²œ ìƒì„±

### âœ¨ í•µì‹¬ íŠ¹ì§•

1. **í™˜ê° ë°©ì§€**: RAGë¡œ ì‹¤ì œ í•™ê³¼ ì •ë³´ë§Œ ì¶”ì²œ
2. **í•œêµ­ì–´ ìµœì í™”**: í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© + LLM
3. **êµ¬ì¡°í™”ëœ ì¶œë ¥**: Pydantic Output Parser ì‚¬ìš©
4. **ìœ ì—°í•œ í”„ë¡¬í”„íŠ¸**: LangChain PromptTemplate

---

## ì‹œì‘í•˜ê¸°

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- **Docker & Docker Compose** ì„¤ì¹˜
- **GPU ê¶Œì¥**: NVIDIA GPU (8GB VRAM ì´ìƒ)
  - RTX 3060 12GB, RTX 4070, RTX 5070 ë“± ìµœì 
  - NVIDIA Container Toolkit ì„¤ì¹˜ í•„ìš”
- ìµœì†Œ 16GB RAM (32GB ê¶Œì¥)
- ë””ìŠ¤í¬ ê³µê°„: ìµœì†Œ 10GB

### ì„¤ì¹˜ ë° ì‹¤í–‰

#### 1. í”„ë¡œì íŠ¸ í´ë¡ 

```bash
git clone <repository-url>
cd PathFinder
```

#### 2. Docker Composeë¡œ ì„œë¹„ìŠ¤ ì‹¤í–‰

```bash
docker-compose up -d
```

ì„œë¹„ìŠ¤ê°€ ì‹œì‘ë©ë‹ˆë‹¤:
- `frontend`: React ì›¹ UI (í¬íŠ¸ 3000) ğŸŒ
- `api`: FastAPI ì„œë²„ (í¬íŠ¸ 8000)
- `ollama`: LLM ì„œë²„ (í¬íŠ¸ 11434)
- `qdrant`: Vector DB (í¬íŠ¸ 6333, 6334)

#### 3. LLM ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)

```bash
# EXAONE-3.5-7.8B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (í•œêµ­ì–´ ë„¤ì´í‹°ë¸Œ, 12GB GPU ìµœì í™”)
docker exec -it pathfinder-ollama ollama pull exaone3.5:7.8b

# ëª¨ë¸ í™•ì¸
docker exec -it pathfinder-ollama ollama list
```

**VRAM ìš”êµ¬ì‚¬í•­**: ~6GB (RTX 3060 12GB, RTX 4070, RTX 5070 ë“±ì— ìµœì )

#### 4. Vector DB ì´ˆê¸°í™” (ìµœì´ˆ 1íšŒ)

```bash
curl -X POST http://localhost:8000/initialize-db
```

34ê°œ í•™ê³¼ ë°ì´í„°ê°€ ì„ë² ë”©ë˜ì–´ Qdrantì— ì €ì¥ë©ë‹ˆë‹¤.

#### 5. ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†

```
http://localhost:3000
```

ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ í•™ê³¼ ì¶”ì²œì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ“

ë˜ëŠ” APIë¥¼ ì§ì ‘ í˜¸ì¶œ:

```bash
curl http://localhost:8000/health
```

---

## ì‚¬ìš© ë°©ë²•

### ğŸ’» ì›¹ UI ì‚¬ìš© (ì¶”ì²œ)

1. ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:3000` ì ‘ì†
2. ê´€ì‹¬ì‚¬ ì…ë ¥ (ì˜ˆ: "í”„ë¡œê·¸ë˜ë°, AI, ìˆ˜í•™")
3. "í•™ê³¼ ì¶”ì²œ ë°›ê¸°" ë²„íŠ¼ í´ë¦­
4. AIê°€ ë¶„ì„í•œ ì¶”ì²œ í•™ê³¼ì™€ ìƒì„¸ ì„¤ëª… í™•ì¸

### ğŸ”§ API ì§ì ‘ í˜¸ì¶œ

#### API ë¬¸ì„œ

ì„œë¹„ìŠ¤ ì‹¤í–‰ í›„:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸

#### 1. í•™ê³¼ ì¶”ì²œ (RAG)

```bash
curl -X POST http://localhost:8000/recommend \
  -H "Content-Type: application/json" \
  -d '{
    "interests": "í”„ë¡œê·¸ë˜ë°, ê²Œì„ ê°œë°œ, ìˆ˜í•™"
  }'
```

**ì‘ë‹µ ì˜ˆì‹œ:**

```json
{
  "recommendation_id": "550e8400-e29b-41d4-a716-446655440000",
  "recommended_majors": [
    "ì»´í“¨í„°ê³µí•™ê³¼",
    "ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼",
    "ê²Œì„ê³µí•™ê³¼",
    "ì¸ê³µì§€ëŠ¥í•™ê³¼",
    "ë°ì´í„°ì‚¬ì´ì–¸ìŠ¤í•™ê³¼"
  ],
  "reasoning": "í•™ìƒì˜ ê´€ì‹¬ì‚¬ì¸ í”„ë¡œê·¸ë˜ë°ê³¼ ê²Œì„ ê°œë°œì— ê°€ì¥ ì í•©í•œ í•™ê³¼ë“¤ì…ë‹ˆë‹¤...",
  "retrieved_context": [
    {
      "score": 0.85,
      "major_name": "ì»´í“¨í„°ê³µí•™ê³¼",
      "category": "ê³µí•™",
      "description": "...",
      "keywords": ["í”„ë¡œê·¸ë˜ë°", "ì½”ë”©", "..."],
      "career_paths": ["ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´", "..."]
    }
  ]
}
```

#### 2. ë²¡í„° ê²€ìƒ‰ë§Œ ìˆ˜í–‰ (LLM ì—†ìŒ)

```bash
curl -X POST http://localhost:8000/search \
  -H "Content-Type: application/json" \
  -d '{
    "interests": "ì˜ˆìˆ , ë¯¸ìˆ , ë””ìì¸"
  }'
```

ë¹ ë¥¸ ì‘ë‹µì´ í•„ìš”í•˜ê±°ë‚˜ ê²€ìƒ‰ ê²°ê³¼ë§Œ í™•ì¸í•˜ê³  ì‹¶ì„ ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.

#### 3. ê°œë°œì ë„êµ¬

```bash
# í˜„ì¬ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ í™•ì¸
curl http://localhost:8000/debug/prompt
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
PathFinder/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ (189ì¤„)
â”‚   â”œâ”€â”€ rag.py              # LangChain RAG ì‹œìŠ¤í…œ (258ì¤„)
â”‚   â””â”€â”€ initialize_db.py    # Vector DB ì´ˆê¸°í™” (117ì¤„)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ majors.json         # í•™ê³¼ ì •ë³´ (34ê°œ)
â”œâ”€â”€ docker-compose.yml      # ì„œë¹„ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ (3ê°œ ì„œë¹„ìŠ¤)
â”œâ”€â”€ Dockerfile              # API ì„œë²„ ì´ë¯¸ì§€
â”œâ”€â”€ requirements.txt        # Python ì˜ì¡´ì„±
â””â”€â”€ README.md
```

---

## LangChain ì•„í‚¤í…ì²˜

### RAG íŒŒì´í”„ë¼ì¸

```
ì‚¬ìš©ì ê´€ì‹¬ì‚¬ ì…ë ¥
       â†“
[ì„ë² ë”© ë³€í™˜] (HuggingFace Embeddings)
       â†“
[ë²¡í„° ê²€ìƒ‰] (Qdrant VectorStore)
       â†“
ê²€ìƒ‰ëœ í•™ê³¼ ì •ë³´ (Top 5)
       â†“
[í”„ë¡¬í”„íŠ¸ êµ¬ì„±] (PromptTemplate)
       â†“
[LLM ìƒì„±] (Ollama)
       â†“
[ì¶œë ¥ íŒŒì‹±] (PydanticOutputParser)
       â†“
êµ¬ì¡°í™”ëœ ì¶”ì²œ ê²°ê³¼
```

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### 1. **VectorStore** (langchain_qdrant)

```python
vectorstore = QdrantVectorStore.from_existing_collection(
    embedding=embeddings,
    collection_name="majors",
    url=qdrant_host
)
```

#### 2. **Embeddings** (HuggingFace)

```python
embeddings = HuggingFaceEmbeddings(
    model_name="jhgan/ko-sroberta-multitask",  # í•œêµ­ì–´ íŠ¹í™”
    encode_kwargs={'normalize_embeddings': True}
)
```

#### 3. **LLM** (Ollama)

```python
llm = OllamaLLM(
    model="exaone3.5:7.8b",  # LG AI í•œêµ­ì–´ ë„¤ì´í‹°ë¸Œ
    base_url=ollama_host,
    temperature=0.7,
    system="Korean university counselor (pure Hangul)"
)
```

#### 4. **Output Parser** (Pydantic)

```python
class MajorRecommendation(BaseModel):
    recommended_majors: List[str]
    reasoning: str

parser = PydanticOutputParser(pydantic_object=MajorRecommendation)
```

---

## í•™ê³¼ ë°ì´í„°

**34ê°œ í•™ê³¼** í¬í•¨:
- ê³µí•™ (ì»´í“¨í„°, ì†Œí”„íŠ¸ì›¨ì–´, AI, ì „ì, ê¸°ê³„ ë“±)
- ìƒê²½ (ê²½ì˜, ê²½ì œ, íšŒê³„ ë“±)
- ì˜ë£Œ (ì˜í•™, ê°„í˜¸ ë“±)
- êµìœ¡ (êµìœ¡í•™ ë“±)
- ì˜ˆìˆ  (ë””ìì¸, ìŒì•… ë“±)

ê° í•™ê³¼ ì •ë³´:
- ì´ë¦„, ë¶„ì•¼, ì„¤ëª…
- í‚¤ì›Œë“œ (10ê°œ)
- ì§„ë¡œ (5ê°œ)
- ê´€ë ¨ ê³¼ëª©, í•„ìš” ì—­ëŸ‰

---

## ê°œë°œ

### ë¡œì»¬ ê°œë°œ (Docker ì—†ì´)

```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# Ollama ì„¤ì¹˜ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
# https://ollama.aiì—ì„œ Ollama ì„¤ì¹˜
ollama pull exaone3.5:7.8b

# Qdrant ì‹¤í–‰ (Docker)
docker run -p 6333:6333 qdrant/qdrant

# Vector DB ì´ˆê¸°í™”
python src/initialize_db.py

# ì„œë²„ ì‹¤í–‰
uvicorn src.main:app --reload
```

### ë¡œê·¸ í™•ì¸

```bash
# ì „ì²´ ë¡œê·¸
docker-compose logs -f

# API ì„œë²„ë§Œ
docker-compose logs -f api

# Ollamaë§Œ
docker-compose logs -f ollama
```

### ì„œë¹„ìŠ¤ ì¤‘ì§€

```bash
docker-compose down

# ë³¼ë¥¨ê¹Œì§€ ì‚­ì œ (ëª¨ë¸ ìºì‹œ, Vector DB í¬í•¨)
docker-compose down -v
```

---

## LangChainì˜ ì¥ì 

### âœ… ì´ í”„ë¡œì íŠ¸ì—ì„œ í™œìš©í•œ ê¸°ëŠ¥

1. **VectorStore ì¶”ìƒí™”**
   - Qdrant, Pinecone, Chroma ë“± ì‰½ê²Œ êµì²´ ê°€ëŠ¥
   - ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤

2. **PromptTemplate**
   - ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸
   - ë³€ìˆ˜ ì£¼ì…, ê²€ì¦

3. **Output Parser**
   - êµ¬ì¡°í™”ëœ ì¶œë ¥ ë³´ì¥
   - ìë™ ì¬ì‹œë„ (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)

4. **Embeddings í†µí•©**
   - OpenAI, HuggingFace, Cohere ë“±
   - í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤

5. **Document ëª¨ë¸**
   - `page_content` + `metadata` êµ¬ì¡°
   - ê²€ìƒ‰ ë° í•„í„°ë§ ìš©ì´

### ğŸ¯ í–¥í›„ í™•ì¥ ê°€ëŠ¥ì„±

- **ConversationChain**: ëŒ€í™”í˜• ìƒë‹´
- **Agent**: ì—¬ëŸ¬ ë„êµ¬ ì¡°í•© (ì›¹ ê²€ìƒ‰, ê³„ì‚°ê¸° ë“±)
- **Memory**: ëŒ€í™” ì´ë ¥ ê´€ë¦¬
- **LangSmith**: í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Ollama ì—°ê²° ì‹¤íŒ¨

```bash
# Ollama ìƒíƒœ í™•ì¸
docker logs pathfinder-ollama

# í—¬ìŠ¤ì²´í¬ ëŒ€ê¸° (ìµœëŒ€ 1-2ë¶„)
```

### ë©”ëª¨ë¦¬/VRAM ë¶€ì¡±

- Docker Desktop ë©”ëª¨ë¦¬ í• ë‹¹ ì¦ê°€ (ìµœì†Œ 16GB)
- ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© (`KOREAN_LLM_GUIDE.md` ì°¸ê³ ):
  - `yanolja/EEVE-Korean-10.8B` (8GB VRAM)
  - `exaone3.5:7.8b` (6GB VRAM)

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ëŠë¦¼

- ì²« ì‹¤í–‰ ì‹œ 18-20GB ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- ë„¤íŠ¸ì›Œí¬ì— ë”°ë¼ 30ë¶„~1ì‹œê°„ ì†Œìš”

### GPU ì‚¬ìš© í™•ì¸

```bash
# Ollama GPU ì‚¬ìš© í™•ì¸
docker logs pathfinder-ollama | grep GPU

# NVIDIA Docker Runtime í•„ìš”
nvidia-smi
```

---

## ë¡œë“œë§µ

### âœ… Phase 1: LangChain RAG (ì™„ë£Œ)
- [x] LangChain ê¸°ë°˜ RAG ì‹œìŠ¤í…œ
- [x] Qdrant VectorStore í†µí•©
- [x] Pydantic Output Parser
- [x] PromptTemplate ê´€ë¦¬

### ğŸš§ Phase 2: ê¸°ëŠ¥ í™•ì¥ (ì§„í–‰ ì¤‘)
- [ ] ëŒ€í™”í˜• ìƒë‹´ (ConversationChain)
- [ ] í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

### ğŸ“… Phase 3: í”„ë¡œë•ì…˜ (ê³„íš)
- [ ] LangSmith í†µí•©
- [ ] ìºì‹± ë° ì„±ëŠ¥ ìµœì í™”
- [ ] A/B í…ŒìŠ¤íŒ…

---

## ë¼ì´ì„ ìŠ¤

MIT License

---

## ê¸°ìˆ  ë¸”ë¡œê·¸

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒ ê°œë…ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤:

- **RAG (Retrieval-Augmented Generation)**
- **LangChain í”„ë ˆì„ì›Œí¬**
- **Vector Databases**
- **í•œêµ­ì–´ NLP**
- **Docker ê¸°ë°˜ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤**

---

## ì°¸ê³  ìë£Œ

- [LangChain ê³µì‹ ë¬¸ì„œ](https://python.langchain.com/)
- [Qdrant ê³µì‹ ë¬¸ì„œ](https://qdrant.tech/)
- [Ollama ê³µì‹ ì‚¬ì´íŠ¸](https://ollama.ai/)
- [HuggingFace Sentence-Transformers](https://www.sbert.net/)
